{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f429284",
   "metadata": {},
   "source": [
    "\n",
    "# Generative Adversarial Network (GAN) on MNIST\n",
    "\n",
    "This notebook demonstrates the implementation of a **Generative Adversarial Network (GAN)** to generate images of handwritten digits similar to those in the MNIST dataset. GANs consist of two neural networks:\n",
    "- **Generator**: Generates fake images to mimic the real data.\n",
    "- **Discriminator**: Distinguishes between real and fake images.\n",
    "\n",
    "The two networks are trained simultaneously in an adversarial manner: the generator tries to fool the discriminator, while the discriminator tries to accurately classify real and fake images.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04a55f",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Loading and Preprocessing the MNIST Dataset\n",
    "\n",
    "We use the MNIST dataset, which contains grayscale images of handwritten digits (0-9) with size 28x28 pixels. Images are normalized to the range [-1, 1] to suit the `tanh` activation function in the generator's output layer.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a167338",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Architecture of the Generator\n",
    "\n",
    "The **generator** takes a random noise vector (latent space) as input and produces an image that aims to mimic real data. It uses:\n",
    "- Fully connected layers with increasing dimensions.\n",
    "- Batch Normalization to stabilize training.\n",
    "- LeakyReLU activations for intermediate layers.\n",
    "- `tanh` activation for the output layer to generate pixel values in the range [-1, 1].\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942ecb1",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Architecture of the Discriminator\n",
    "\n",
    "The **discriminator** takes an image as input and outputs a probability of whether the image is real or fake. It uses:\n",
    "- Fully connected layers with decreasing dimensions.\n",
    "- Dropout to prevent overfitting.\n",
    "- LeakyReLU activations for all layers except the output.\n",
    "- `sigmoid` activation for the output layer to produce probabilities.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7bf0a",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Training Procedure\n",
    "\n",
    "The GAN is trained in two steps per iteration:\n",
    "1. **Discriminator Training**: The discriminator is trained to maximize its ability to distinguish between real and fake images.\n",
    "2. **Generator Training**: The generator is trained to minimize the discriminator's ability to distinguish between real and fake images.\n",
    "\n",
    "### Loss Functions\n",
    "- **Binary Cross-Entropy Loss**: Used for both the generator and the discriminator.\n",
    "- **Real Labels**: Set to 1 (with optional smoothing or noise).\n",
    "- **Fake Labels**: Set to 0 (with optional smoothing or noise).\n",
    "\n",
    "### Optimizers\n",
    "- **Adam Optimizer** is used for both networks with different learning rates for generator and discriminator.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733dfe99",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Evaluation Metrics\n",
    "\n",
    "We use the following metrics to evaluate the performance of the GAN:\n",
    "1. **Frechet Inception Distance (FID)**: Measures the distance between the distributions of real and generated data.\n",
    "2. **Inception Score (IS)**: Evaluates the diversity and quality of generated data.\n",
    "3. **Kernel Inception Distance (KID)**: Measures the similarity between real and generated data.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c0926d",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Visualizing Results\n",
    "\n",
    "After each training epoch:\n",
    "- Generated images are saved and visualized in a grid (8x8).\n",
    "- Real images from the dataset are also visualized for comparison.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgWx67fgdDdN",
    "outputId": "20e92244-6f47-4999-9e93-55b4deabb4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (1.26.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (11.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (0.20.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.2)\n",
      "Requirement already satisfied: torch-fidelity in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (11.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.13.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (4.66.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-fid\n",
    "!pip install torch-fidelity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DQ3HrEmnwW5K"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_fidelity import calculate_metrics\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "# [EN] Гиперпараметры\n",
    "latent_dim = 128      # [EN] Размер латентного пространства\n",
    "img_size = 28         # [EN] Размер изображения\n",
    "channels = 1          # [EN] Количество каналов\n",
    "batch_size = 64       # [EN] Размер батча\n",
    "lr_g = 0.0001         # [EN] Скорость обучения генератора\n",
    "lr_d = 0.0004         # [EN] Скорость обучения дискриминатора\n",
    "epochs = 50           # [EN] Количество эпох\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# [EN] Датасет и загрузчик данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # [EN] Нормализация в диапазон [-1, 1]\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "86_j3MuYwevc"
   },
   "outputs": [],
   "source": [
    "# [EN] Улучшенный генератор\n",
    "class ImprovedGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_size, channels):\n",
    "        super(ImprovedGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, img_size * img_size * channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(img.size(0), channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hc6qI9Aqwe_x"
   },
   "outputs": [],
   "source": [
    "\n",
    "# [EN] Улучшенный дискриминатор\n",
    "class ImprovedDiscriminator(nn.Module):\n",
    "    def __init__(self, img_size, channels):\n",
    "        super(ImprovedDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size * channels, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        return self.model(img_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o72Wl5iBwzBf"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "def generate_and_save_images(generator, epoch, fake_images, real_images, num_images=10):\n",
    "\n",
    "# [EN] Создаём директорию, если её нет\n",
    "    output_dir = \"./generated_images\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # [EN] Пути для сохранения\n",
    "    fake_path = os.path.join(output_dir, f\"fid_fake_epoch_{epoch}.png\")\n",
    "    real_path = os.path.join(output_dir, f\"fid_real_epoch_{epoch}.png\")\n",
    "\n",
    "    # [EN] Сохраняем изображения\n",
    "    save_image(fake_images[:64], fake_path)  # [EN] Первые 64 изображения\n",
    "    save_image(real_images[:64], real_path)\n",
    "\n",
    "    print(f\"Fake images saved to: {fake_path}\")\n",
    "    print(f\"Real images saved to: {real_path}\")\n",
    "\n",
    "\n",
    "generator = ImprovedGenerator(latent_dim, img_size, channels).to(device)\n",
    "discriminator = ImprovedDiscriminator(img_size, channels).to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "\n",
    "adversarial_loss = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YHVpMY7NYfOu"
   },
   "outputs": [],
   "source": [
    "# [EN] import matplotlib.pyplot as plt\n",
    "# [EN] import numpy as np\n",
    "\n",
    "# [EN] def generate_and_save_images(generator, epoch, num_images=10):\n",
    "# [EN]     # [EN] Переходим в режим оценки (evaluation mode)\n",
    "# [EN]     generator.eval()\n",
    "\n",
    "# [EN]     # [EN] Генерируем случайный шум\n",
    "# [EN]     z = torch.randn(num_images, latent_dim).to(device)\n",
    "\n",
    "# [EN]     # [EN] Генерируем изображения\n",
    "# [EN]     fake_imgs = generator(z).cpu().detach()\n",
    "\n",
    "# [EN]     # [EN] Преобразуем диапазон [-1, 1] обратно в [0, 1]\n",
    "# [EN]     fake_imgs = (fake_imgs + 1) / 2\n",
    "\n",
    "# [EN]     # [EN] Создаем фигуру\n",
    "# [EN]     plt.figure(figsize=(15, 5))\n",
    "# [EN]     for i in range(num_images):\n",
    "# [EN]         plt.subplot(1, num_images, i + 1)\n",
    "# [EN]         plt.imshow(fake_imgs[i][0], cmap='gray')\n",
    "# [EN]         plt.axis('off')\n",
    "# [EN]     plt.suptitle(f\"Epoch {epoch}\")\n",
    "# [EN]     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jpt9BX5ZdTf1"
   },
   "outputs": [],
   "source": [
    "from torch_fidelity import calculate_metrics\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "def calculate_all_metrics(generator, real_data_loader, epoch, latent_dim, device, num_images=64):\n",
    "    generator.eval()\n",
    "    fake_images = []\n",
    "    real_images = []\n",
    "\n",
    "    # [EN] Генерация фейковых изображений\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_images, latent_dim).to(device)\n",
    "        fake_imgs = generator(z).cpu()\n",
    "        fake_images = (fake_imgs + 1) / 2  # [EN] Перевод в диапазон [0, 1]\n",
    "\n",
    "    # [EN] Сбор реальных изображений\n",
    "    for real_imgs, _ in real_data_loader:\n",
    "        real_imgs = (real_imgs + 1) / 2  # [EN] Перевод в диапазон [0, 1]\n",
    "        real_images.append(real_imgs)\n",
    "        if len(real_images) * real_imgs.size(0) >= num_images:\n",
    "            break\n",
    "\n",
    "    real_images = torch.cat(real_images, dim=0)[:num_images]\n",
    "    fake_images = fake_images[:num_images]\n",
    "\n",
    "    # [EN] Создание директорий для сохранения изображений\n",
    "    fake_path = f\"./metrics/fake_epoch_{epoch}\"\n",
    "    real_path = f\"./metrics/real_epoch_{epoch}\"\n",
    "    os.makedirs(fake_path, exist_ok=True)\n",
    "    os.makedirs(real_path, exist_ok=True)\n",
    "\n",
    "    # [EN] Сохранение изображений на диск\n",
    "    for i, img in enumerate(fake_images):\n",
    "        torchvision.utils.save_image(img, f\"{fake_path}/img_{i}.png\")\n",
    "    for i, img in enumerate(real_images):\n",
    "        torchvision.utils.save_image(img, f\"{real_path}/img_{i}.png\")\n",
    "\n",
    "    # [EN] Вычисление всех метрик через директории\n",
    "    metrics = calculate_metrics(\n",
    "        input1=fake_path,  # [EN] Путь к сгенерированным изображениям\n",
    "        input2=real_path,  # [EN] Путь к реальным изображениям\n",
    "        cuda=torch.cuda.is_available(),\n",
    "        isc=True,  # [EN] Включаем Inception Score\n",
    "        fid=True,  # [EN] Включаем FID\n",
    "        kid=True,  # [EN] Включаем KID\n",
    "        kid_subset_size=num_images  # [EN] Устанавливаем размер подвыборки для KID\n",
    "    )\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2NCCkbxX5EF",
    "outputId": "392de28e-611b-4d38-f289-81ad3bdaac00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Batch [0/938] Loss D: 1.3975, Loss G: 0.7125\n",
      "Epoch [1/50] Batch [100/938] Loss D: 1.2315, Loss G: 0.8621\n",
      "Epoch [1/50] Batch [200/938] Loss D: 1.0749, Loss G: 1.1395\n",
      "Epoch [1/50] Batch [300/938] Loss D: 0.9927, Loss G: 1.2133\n",
      "Epoch [1/50] Batch [400/938] Loss D: 1.3794, Loss G: 1.6816\n",
      "Epoch [1/50] Batch [500/938] Loss D: 1.0434, Loss G: 0.8030\n",
      "Epoch [1/50] Batch [600/938] Loss D: 1.2263, Loss G: 1.9170\n",
      "Epoch [1/50] Batch [700/938] Loss D: 1.1540, Loss G: 1.3059\n",
      "Epoch [1/50] Batch [800/938] Loss D: 1.0582, Loss G: 1.3081\n",
      "Epoch [1/50] Batch [900/938] Loss D: 1.7232, Loss G: 0.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_1\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "/usr/local/lib/python3.10/dist-packages/torch_fidelity/datasets.py:16: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes())).view(height, width, 3)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_1\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7088734608701759 ± 0.27774356300449216\n",
      "Frechet Inception Distance: 268.64687742661243\n",
      "Kernel Inception Distance: 0.26171856297387014 ± 1.4269948491778967e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_1.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_1.png\n",
      "Epoch [1/50] Metrics:\n",
      "  Inception Score (IS): 1.708873\n",
      "  Frechet Inception Distance (FID): 268.646877\n",
      "  Kernel Inception Distance (KID): 0.261719\n",
      "Epoch [2/50] Batch [0/938] Loss D: 0.9761, Loss G: 1.0448\n",
      "Epoch [2/50] Batch [100/938] Loss D: 0.9790, Loss G: 1.0781\n",
      "Epoch [2/50] Batch [200/938] Loss D: 1.3495, Loss G: 1.5524\n",
      "Epoch [2/50] Batch [300/938] Loss D: 0.9938, Loss G: 1.0945\n",
      "Epoch [2/50] Batch [400/938] Loss D: 0.9997, Loss G: 1.2980\n",
      "Epoch [2/50] Batch [500/938] Loss D: 1.1414, Loss G: 1.2169\n",
      "Epoch [2/50] Batch [600/938] Loss D: 0.9020, Loss G: 1.5148\n",
      "Epoch [2/50] Batch [700/938] Loss D: 1.0342, Loss G: 2.5011\n",
      "Epoch [2/50] Batch [800/938] Loss D: 1.1262, Loss G: 1.0004\n",
      "Epoch [2/50] Batch [900/938] Loss D: 1.0506, Loss G: 0.7494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_2\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_2\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.5958896037924253 ± 0.22066978259589742\n",
      "Frechet Inception Distance: 237.98634637923692\n",
      "Kernel Inception Distance: 0.24426375370176998 ± 8.98113641826504e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_2.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_2.png\n",
      "Epoch [2/50] Metrics:\n",
      "  Inception Score (IS): 1.595890\n",
      "  Frechet Inception Distance (FID): 237.986346\n",
      "  Kernel Inception Distance (KID): 0.244264\n",
      "Epoch [3/50] Batch [0/938] Loss D: 0.9728, Loss G: 1.8482\n",
      "Epoch [3/50] Batch [100/938] Loss D: 0.9934, Loss G: 1.1998\n",
      "Epoch [3/50] Batch [200/938] Loss D: 1.0897, Loss G: 1.4347\n",
      "Epoch [3/50] Batch [300/938] Loss D: 0.9765, Loss G: 1.7250\n",
      "Epoch [3/50] Batch [400/938] Loss D: 1.0389, Loss G: 1.3324\n",
      "Epoch [3/50] Batch [500/938] Loss D: 0.9870, Loss G: 1.7966\n",
      "Epoch [3/50] Batch [600/938] Loss D: 0.9172, Loss G: 1.9084\n",
      "Epoch [3/50] Batch [700/938] Loss D: 1.1135, Loss G: 1.6912\n",
      "Epoch [3/50] Batch [800/938] Loss D: 1.0560, Loss G: 0.9560\n",
      "Epoch [3/50] Batch [900/938] Loss D: 1.1123, Loss G: 1.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_3\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_3\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.5096478336507668 ± 0.14008470760206745\n",
      "Frechet Inception Distance: 260.6583210530637\n",
      "Kernel Inception Distance: 0.26940963211513697 ± 1.179652017752779e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_3.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_3.png\n",
      "Epoch [3/50] Metrics:\n",
      "  Inception Score (IS): 1.509648\n",
      "  Frechet Inception Distance (FID): 260.658321\n",
      "  Kernel Inception Distance (KID): 0.269410\n",
      "Epoch [4/50] Batch [0/938] Loss D: 1.0348, Loss G: 1.2354\n",
      "Epoch [4/50] Batch [100/938] Loss D: 1.0387, Loss G: 1.5734\n",
      "Epoch [4/50] Batch [200/938] Loss D: 1.1455, Loss G: 1.3999\n",
      "Epoch [4/50] Batch [300/938] Loss D: 0.9806, Loss G: 1.4761\n",
      "Epoch [4/50] Batch [400/938] Loss D: 1.0288, Loss G: 1.2846\n",
      "Epoch [4/50] Batch [500/938] Loss D: 1.0840, Loss G: 1.3177\n",
      "Epoch [4/50] Batch [600/938] Loss D: 1.0958, Loss G: 1.1638\n",
      "Epoch [4/50] Batch [700/938] Loss D: 1.1202, Loss G: 1.1920\n",
      "Epoch [4/50] Batch [800/938] Loss D: 1.1242, Loss G: 0.9670\n",
      "Epoch [4/50] Batch [900/938] Loss D: 1.1935, Loss G: 1.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_4\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_4\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.5407457107905755 ± 0.09636535300615935\n",
      "Frechet Inception Distance: 199.23414647360588\n",
      "Kernel Inception Distance: 0.17456409715470803 ± 1.3290882677161164e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_4.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_4.png\n",
      "Epoch [4/50] Metrics:\n",
      "  Inception Score (IS): 1.540746\n",
      "  Frechet Inception Distance (FID): 199.234146\n",
      "  Kernel Inception Distance (KID): 0.174564\n",
      "Epoch [5/50] Batch [0/938] Loss D: 1.0808, Loss G: 1.0698\n",
      "Epoch [5/50] Batch [100/938] Loss D: 1.0489, Loss G: 1.2554\n",
      "Epoch [5/50] Batch [200/938] Loss D: 1.1498, Loss G: 1.1481\n",
      "Epoch [5/50] Batch [300/938] Loss D: 1.2839, Loss G: 0.7874\n",
      "Epoch [5/50] Batch [400/938] Loss D: 1.2355, Loss G: 1.2602\n",
      "Epoch [5/50] Batch [500/938] Loss D: 1.1078, Loss G: 1.0027\n",
      "Epoch [5/50] Batch [600/938] Loss D: 1.2151, Loss G: 1.0798\n",
      "Epoch [5/50] Batch [700/938] Loss D: 1.1094, Loss G: 0.7829\n",
      "Epoch [5/50] Batch [800/938] Loss D: 1.0929, Loss G: 1.0134\n",
      "Epoch [5/50] Batch [900/938] Loss D: 1.1367, Loss G: 1.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_5\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_5\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8321567920844166 ± 0.14348330650019706\n",
      "Frechet Inception Distance: 206.00079447434817\n",
      "Kernel Inception Distance: 0.1887782574078395 ± 8.037829683030485e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_5.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_5.png\n",
      "Epoch [5/50] Metrics:\n",
      "  Inception Score (IS): 1.832157\n",
      "  Frechet Inception Distance (FID): 206.000794\n",
      "  Kernel Inception Distance (KID): 0.188778\n",
      "Epoch [6/50] Batch [0/938] Loss D: 1.3063, Loss G: 1.0394\n",
      "Epoch [6/50] Batch [100/938] Loss D: 1.2155, Loss G: 0.7644\n",
      "Epoch [6/50] Batch [200/938] Loss D: 1.1770, Loss G: 1.0520\n",
      "Epoch [6/50] Batch [300/938] Loss D: 1.1293, Loss G: 0.9640\n",
      "Epoch [6/50] Batch [400/938] Loss D: 1.1585, Loss G: 1.1434\n",
      "Epoch [6/50] Batch [500/938] Loss D: 1.2218, Loss G: 1.1652\n",
      "Epoch [6/50] Batch [600/938] Loss D: 1.2034, Loss G: 1.0057\n",
      "Epoch [6/50] Batch [700/938] Loss D: 1.2361, Loss G: 0.9612\n",
      "Epoch [6/50] Batch [800/938] Loss D: 1.1933, Loss G: 1.1498\n",
      "Epoch [6/50] Batch [900/938] Loss D: 1.1284, Loss G: 0.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_6\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_6\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.6426637292999042 ± 0.27821586847868085\n",
      "Frechet Inception Distance: 191.80916987938036\n",
      "Kernel Inception Distance: 0.16755464126193345 ± 1.5460116590948925e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_6.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_6.png\n",
      "Epoch [6/50] Metrics:\n",
      "  Inception Score (IS): 1.642664\n",
      "  Frechet Inception Distance (FID): 191.809170\n",
      "  Kernel Inception Distance (KID): 0.167555\n",
      "Epoch [7/50] Batch [0/938] Loss D: 1.1843, Loss G: 0.8869\n",
      "Epoch [7/50] Batch [100/938] Loss D: 1.2677, Loss G: 1.1261\n",
      "Epoch [7/50] Batch [200/938] Loss D: 1.2671, Loss G: 0.6983\n",
      "Epoch [7/50] Batch [300/938] Loss D: 1.2682, Loss G: 0.8318\n",
      "Epoch [7/50] Batch [400/938] Loss D: 1.2006, Loss G: 1.2565\n",
      "Epoch [7/50] Batch [500/938] Loss D: 1.2742, Loss G: 1.2008\n",
      "Epoch [7/50] Batch [600/938] Loss D: 1.1952, Loss G: 0.8937\n",
      "Epoch [7/50] Batch [700/938] Loss D: 1.1342, Loss G: 0.8186\n",
      "Epoch [7/50] Batch [800/938] Loss D: 1.2485, Loss G: 1.1907\n",
      "Epoch [7/50] Batch [900/938] Loss D: 1.1786, Loss G: 1.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_7\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_7\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7506865605279305 ± 0.16931664039382088\n",
      "Frechet Inception Distance: 177.99030635084296\n",
      "Kernel Inception Distance: 0.13333017860140126 ± 1.3244016289808557e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_7.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_7.png\n",
      "Epoch [7/50] Metrics:\n",
      "  Inception Score (IS): 1.750687\n",
      "  Frechet Inception Distance (FID): 177.990306\n",
      "  Kernel Inception Distance (KID): 0.133330\n",
      "Epoch [8/50] Batch [0/938] Loss D: 1.2474, Loss G: 0.7434\n",
      "Epoch [8/50] Batch [100/938] Loss D: 1.1776, Loss G: 0.8373\n",
      "Epoch [8/50] Batch [200/938] Loss D: 1.2542, Loss G: 0.8611\n",
      "Epoch [8/50] Batch [300/938] Loss D: 1.1351, Loss G: 0.8086\n",
      "Epoch [8/50] Batch [400/938] Loss D: 1.3807, Loss G: 0.9282\n",
      "Epoch [8/50] Batch [500/938] Loss D: 1.3151, Loss G: 1.0729\n",
      "Epoch [8/50] Batch [600/938] Loss D: 1.1959, Loss G: 0.9450\n",
      "Epoch [8/50] Batch [700/938] Loss D: 1.2978, Loss G: 0.9410\n",
      "Epoch [8/50] Batch [800/938] Loss D: 1.2960, Loss G: 1.0826\n",
      "Epoch [8/50] Batch [900/938] Loss D: 1.1936, Loss G: 0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_8\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_8\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.6733371914472297 ± 0.2417878647048486\n",
      "Frechet Inception Distance: 187.16591990475388\n",
      "Kernel Inception Distance: 0.15606464215687346 ± 1.3857399090269892e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_8.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_8.png\n",
      "Epoch [8/50] Metrics:\n",
      "  Inception Score (IS): 1.673337\n",
      "  Frechet Inception Distance (FID): 187.165920\n",
      "  Kernel Inception Distance (KID): 0.156065\n",
      "Epoch [9/50] Batch [0/938] Loss D: 1.2370, Loss G: 1.0059\n",
      "Epoch [9/50] Batch [100/938] Loss D: 1.3112, Loss G: 0.8329\n",
      "Epoch [9/50] Batch [200/938] Loss D: 1.1697, Loss G: 0.8055\n",
      "Epoch [9/50] Batch [300/938] Loss D: 1.2968, Loss G: 1.0264\n",
      "Epoch [9/50] Batch [400/938] Loss D: 1.1657, Loss G: 0.8783\n",
      "Epoch [9/50] Batch [500/938] Loss D: 1.2365, Loss G: 1.0842\n",
      "Epoch [9/50] Batch [600/938] Loss D: 1.3092, Loss G: 1.0949\n",
      "Epoch [9/50] Batch [700/938] Loss D: 1.2300, Loss G: 0.9780\n",
      "Epoch [9/50] Batch [800/938] Loss D: 1.3600, Loss G: 0.7757\n",
      "Epoch [9/50] Batch [900/938] Loss D: 1.3851, Loss G: 0.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_9\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_9\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.6453488250883037 ± 0.20813470211917637\n",
      "Frechet Inception Distance: 197.15460542837968\n",
      "Kernel Inception Distance: 0.1703583070966932 ± 1.7504567628681585e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_9.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_9.png\n",
      "Epoch [9/50] Metrics:\n",
      "  Inception Score (IS): 1.645349\n",
      "  Frechet Inception Distance (FID): 197.154605\n",
      "  Kernel Inception Distance (KID): 0.170358\n",
      "Epoch [10/50] Batch [0/938] Loss D: 1.1618, Loss G: 0.9351\n",
      "Epoch [10/50] Batch [100/938] Loss D: 1.3315, Loss G: 0.8866\n",
      "Epoch [10/50] Batch [200/938] Loss D: 1.1864, Loss G: 0.8387\n",
      "Epoch [10/50] Batch [300/938] Loss D: 1.3259, Loss G: 1.1032\n",
      "Epoch [10/50] Batch [400/938] Loss D: 1.2864, Loss G: 1.0579\n",
      "Epoch [10/50] Batch [500/938] Loss D: 1.3434, Loss G: 0.8290\n",
      "Epoch [10/50] Batch [600/938] Loss D: 1.3086, Loss G: 1.0682\n",
      "Epoch [10/50] Batch [700/938] Loss D: 1.2555, Loss G: 0.9244\n",
      "Epoch [10/50] Batch [800/938] Loss D: 1.3618, Loss G: 1.0020\n",
      "Epoch [10/50] Batch [900/938] Loss D: 1.3312, Loss G: 0.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_10\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_10\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8513995898130418 ± 0.3109840657513786\n",
      "Frechet Inception Distance: 169.43796470288808\n",
      "Kernel Inception Distance: 0.12542875770538564 ± 1.9755788197894601e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_10.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_10.png\n",
      "Epoch [10/50] Metrics:\n",
      "  Inception Score (IS): 1.851400\n",
      "  Frechet Inception Distance (FID): 169.437965\n",
      "  Kernel Inception Distance (KID): 0.125429\n",
      "Epoch [11/50] Batch [0/938] Loss D: 1.2501, Loss G: 1.0123\n",
      "Epoch [11/50] Batch [100/938] Loss D: 1.3080, Loss G: 0.9430\n",
      "Epoch [11/50] Batch [200/938] Loss D: 1.2565, Loss G: 0.9707\n",
      "Epoch [11/50] Batch [300/938] Loss D: 1.2870, Loss G: 0.9460\n",
      "Epoch [11/50] Batch [400/938] Loss D: 1.2293, Loss G: 0.8826\n",
      "Epoch [11/50] Batch [500/938] Loss D: 1.2602, Loss G: 0.9018\n",
      "Epoch [11/50] Batch [600/938] Loss D: 1.3452, Loss G: 0.8455\n",
      "Epoch [11/50] Batch [700/938] Loss D: 1.2584, Loss G: 0.9540\n",
      "Epoch [11/50] Batch [800/938] Loss D: 1.2318, Loss G: 0.8557\n",
      "Epoch [11/50] Batch [900/938] Loss D: 1.3672, Loss G: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_11\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_11\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.819410426872544 ± 0.2378634862000488\n",
      "Frechet Inception Distance: 181.26522807479458\n",
      "Kernel Inception Distance: 0.13154556221432145 ± 1.4210541986170237e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_11.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_11.png\n",
      "Epoch [11/50] Metrics:\n",
      "  Inception Score (IS): 1.819410\n",
      "  Frechet Inception Distance (FID): 181.265228\n",
      "  Kernel Inception Distance (KID): 0.131546\n",
      "Epoch [12/50] Batch [0/938] Loss D: 1.3240, Loss G: 0.8948\n",
      "Epoch [12/50] Batch [100/938] Loss D: 1.3164, Loss G: 0.7916\n",
      "Epoch [12/50] Batch [200/938] Loss D: 1.4002, Loss G: 1.0358\n",
      "Epoch [12/50] Batch [300/938] Loss D: 1.2912, Loss G: 0.7468\n",
      "Epoch [12/50] Batch [400/938] Loss D: 1.2634, Loss G: 0.7996\n",
      "Epoch [12/50] Batch [500/938] Loss D: 1.2610, Loss G: 0.7330\n",
      "Epoch [12/50] Batch [600/938] Loss D: 1.2731, Loss G: 0.8546\n",
      "Epoch [12/50] Batch [700/938] Loss D: 1.3199, Loss G: 0.9245\n",
      "Epoch [12/50] Batch [800/938] Loss D: 1.2732, Loss G: 0.8203\n",
      "Epoch [12/50] Batch [900/938] Loss D: 1.3774, Loss G: 0.9287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_12\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_12\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.638509189279788 ± 0.24771695655940443\n",
      "Frechet Inception Distance: 160.3395774167023\n",
      "Kernel Inception Distance: 0.12538628627383516 ± 9.854165893147767e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_12.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_12.png\n",
      "Epoch [12/50] Metrics:\n",
      "  Inception Score (IS): 1.638509\n",
      "  Frechet Inception Distance (FID): 160.339577\n",
      "  Kernel Inception Distance (KID): 0.125386\n",
      "Epoch [13/50] Batch [0/938] Loss D: 1.2957, Loss G: 0.7634\n",
      "Epoch [13/50] Batch [100/938] Loss D: 1.3247, Loss G: 0.8787\n",
      "Epoch [13/50] Batch [200/938] Loss D: 1.3050, Loss G: 0.8205\n",
      "Epoch [13/50] Batch [300/938] Loss D: 1.3693, Loss G: 0.8879\n",
      "Epoch [13/50] Batch [400/938] Loss D: 1.3069, Loss G: 0.9354\n",
      "Epoch [13/50] Batch [500/938] Loss D: 1.3466, Loss G: 0.8667\n",
      "Epoch [13/50] Batch [600/938] Loss D: 1.2273, Loss G: 0.8516\n",
      "Epoch [13/50] Batch [700/938] Loss D: 1.2911, Loss G: 0.8040\n",
      "Epoch [13/50] Batch [800/938] Loss D: 1.3098, Loss G: 0.9229\n",
      "Epoch [13/50] Batch [900/938] Loss D: 1.2091, Loss G: 0.8739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_13\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_13\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7857770818991994 ± 0.27124839664695366\n",
      "Frechet Inception Distance: 149.01463691612923\n",
      "Kernel Inception Distance: 0.10633545413849856 ± 9.407238569564537e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_13.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_13.png\n",
      "Epoch [13/50] Metrics:\n",
      "  Inception Score (IS): 1.785777\n",
      "  Frechet Inception Distance (FID): 149.014637\n",
      "  Kernel Inception Distance (KID): 0.106335\n",
      "Epoch [14/50] Batch [0/938] Loss D: 1.3181, Loss G: 0.8310\n",
      "Epoch [14/50] Batch [100/938] Loss D: 1.2863, Loss G: 0.7497\n",
      "Epoch [14/50] Batch [200/938] Loss D: 1.2607, Loss G: 0.8907\n",
      "Epoch [14/50] Batch [300/938] Loss D: 1.3000, Loss G: 0.7364\n",
      "Epoch [14/50] Batch [400/938] Loss D: 1.2014, Loss G: 1.0124\n",
      "Epoch [14/50] Batch [500/938] Loss D: 1.3441, Loss G: 0.8592\n",
      "Epoch [14/50] Batch [600/938] Loss D: 1.3622, Loss G: 0.8698\n",
      "Epoch [14/50] Batch [700/938] Loss D: 1.3162, Loss G: 0.8135\n",
      "Epoch [14/50] Batch [800/938] Loss D: 1.2252, Loss G: 0.8662\n",
      "Epoch [14/50] Batch [900/938] Loss D: 1.2963, Loss G: 0.8144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_14\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_14\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8462232701958965 ± 0.25414874740227505\n",
      "Frechet Inception Distance: 172.32326160676195\n",
      "Kernel Inception Distance: 0.13261056029607396 ± 1.3952725733558787e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_14.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_14.png\n",
      "Epoch [14/50] Metrics:\n",
      "  Inception Score (IS): 1.846223\n",
      "  Frechet Inception Distance (FID): 172.323262\n",
      "  Kernel Inception Distance (KID): 0.132611\n",
      "Epoch [15/50] Batch [0/938] Loss D: 1.3005, Loss G: 0.8311\n",
      "Epoch [15/50] Batch [100/938] Loss D: 1.2229, Loss G: 0.9332\n",
      "Epoch [15/50] Batch [200/938] Loss D: 1.2544, Loss G: 0.8479\n",
      "Epoch [15/50] Batch [300/938] Loss D: 1.2324, Loss G: 0.9590\n",
      "Epoch [15/50] Batch [400/938] Loss D: 1.3329, Loss G: 0.9603\n",
      "Epoch [15/50] Batch [500/938] Loss D: 1.2719, Loss G: 0.8206\n",
      "Epoch [15/50] Batch [600/938] Loss D: 1.3712, Loss G: 0.8144\n",
      "Epoch [15/50] Batch [700/938] Loss D: 1.3845, Loss G: 0.8651\n",
      "Epoch [15/50] Batch [800/938] Loss D: 1.2657, Loss G: 0.8459\n",
      "Epoch [15/50] Batch [900/938] Loss D: 1.3755, Loss G: 0.8823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_15\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_15\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8206016154242288 ± 0.2555882904090921\n",
      "Frechet Inception Distance: 150.6287328667865\n",
      "Kernel Inception Distance: 0.10611080873580221 ± 1.2153029684356235e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_15.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_15.png\n",
      "Epoch [15/50] Metrics:\n",
      "  Inception Score (IS): 1.820602\n",
      "  Frechet Inception Distance (FID): 150.628733\n",
      "  Kernel Inception Distance (KID): 0.106111\n",
      "Epoch [16/50] Batch [0/938] Loss D: 1.3861, Loss G: 0.8249\n",
      "Epoch [16/50] Batch [100/938] Loss D: 1.2979, Loss G: 0.7738\n",
      "Epoch [16/50] Batch [200/938] Loss D: 1.2516, Loss G: 0.9167\n",
      "Epoch [16/50] Batch [300/938] Loss D: 1.3200, Loss G: 0.8202\n",
      "Epoch [16/50] Batch [400/938] Loss D: 1.2309, Loss G: 0.8648\n",
      "Epoch [16/50] Batch [500/938] Loss D: 1.3602, Loss G: 0.7927\n",
      "Epoch [16/50] Batch [600/938] Loss D: 1.4115, Loss G: 0.8479\n",
      "Epoch [16/50] Batch [700/938] Loss D: 1.3156, Loss G: 0.8117\n",
      "Epoch [16/50] Batch [800/938] Loss D: 1.4032, Loss G: 0.7970\n",
      "Epoch [16/50] Batch [900/938] Loss D: 1.3788, Loss G: 0.7832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_16\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_16\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7702079890785125 ± 0.3013695700948528\n",
      "Frechet Inception Distance: 155.11186441573489\n",
      "Kernel Inception Distance: 0.10790763942022168 ± 1.6773860369825283e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_16.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_16.png\n",
      "Epoch [16/50] Metrics:\n",
      "  Inception Score (IS): 1.770208\n",
      "  Frechet Inception Distance (FID): 155.111864\n",
      "  Kernel Inception Distance (KID): 0.107908\n",
      "Epoch [17/50] Batch [0/938] Loss D: 1.3438, Loss G: 0.8280\n",
      "Epoch [17/50] Batch [100/938] Loss D: 1.3397, Loss G: 0.7851\n",
      "Epoch [17/50] Batch [200/938] Loss D: 1.3747, Loss G: 0.7887\n",
      "Epoch [17/50] Batch [300/938] Loss D: 1.4141, Loss G: 0.7972\n",
      "Epoch [17/50] Batch [400/938] Loss D: 1.3644, Loss G: 0.9232\n",
      "Epoch [17/50] Batch [500/938] Loss D: 1.3540, Loss G: 0.9309\n",
      "Epoch [17/50] Batch [600/938] Loss D: 1.1983, Loss G: 0.8466\n",
      "Epoch [17/50] Batch [700/938] Loss D: 1.2885, Loss G: 0.8196\n",
      "Epoch [17/50] Batch [800/938] Loss D: 1.2237, Loss G: 0.8606\n",
      "Epoch [17/50] Batch [900/938] Loss D: 1.4173, Loss G: 0.7588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_17\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_17\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.6723000118251647 ± 0.25061255550026224\n",
      "Frechet Inception Distance: 134.20517532861535\n",
      "Kernel Inception Distance: 0.08278987653671749 ± 9.785402004436216e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_17.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_17.png\n",
      "Epoch [17/50] Metrics:\n",
      "  Inception Score (IS): 1.672300\n",
      "  Frechet Inception Distance (FID): 134.205175\n",
      "  Kernel Inception Distance (KID): 0.082790\n",
      "Epoch [18/50] Batch [0/938] Loss D: 1.2890, Loss G: 0.8020\n",
      "Epoch [18/50] Batch [100/938] Loss D: 1.3219, Loss G: 0.8355\n",
      "Epoch [18/50] Batch [200/938] Loss D: 1.2855, Loss G: 0.8363\n",
      "Epoch [18/50] Batch [300/938] Loss D: 1.2962, Loss G: 0.7761\n",
      "Epoch [18/50] Batch [400/938] Loss D: 1.3356, Loss G: 0.7313\n",
      "Epoch [18/50] Batch [500/938] Loss D: 1.3218, Loss G: 0.8888\n",
      "Epoch [18/50] Batch [600/938] Loss D: 1.3066, Loss G: 0.8210\n",
      "Epoch [18/50] Batch [700/938] Loss D: 1.2542, Loss G: 0.8428\n",
      "Epoch [18/50] Batch [800/938] Loss D: 1.3711, Loss G: 0.7581\n",
      "Epoch [18/50] Batch [900/938] Loss D: 1.3113, Loss G: 0.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_18\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_18\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.9103172702389242 ± 0.3066029527248018\n",
      "Frechet Inception Distance: 149.24032234010235\n",
      "Kernel Inception Distance: 0.08794993714680743 ± 1.7120675690429888e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_18.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_18.png\n",
      "Epoch [18/50] Metrics:\n",
      "  Inception Score (IS): 1.910317\n",
      "  Frechet Inception Distance (FID): 149.240322\n",
      "  Kernel Inception Distance (KID): 0.087950\n",
      "Epoch [19/50] Batch [0/938] Loss D: 1.2768, Loss G: 0.7413\n",
      "Epoch [19/50] Batch [100/938] Loss D: 1.3855, Loss G: 0.8438\n",
      "Epoch [19/50] Batch [200/938] Loss D: 1.3602, Loss G: 0.8296\n",
      "Epoch [19/50] Batch [300/938] Loss D: 1.3112, Loss G: 0.8196\n",
      "Epoch [19/50] Batch [400/938] Loss D: 1.2733, Loss G: 0.8515\n",
      "Epoch [19/50] Batch [500/938] Loss D: 1.2967, Loss G: 0.9179\n",
      "Epoch [19/50] Batch [600/938] Loss D: 1.3020, Loss G: 0.7625\n",
      "Epoch [19/50] Batch [700/938] Loss D: 1.3204, Loss G: 0.7953\n",
      "Epoch [19/50] Batch [800/938] Loss D: 1.3387, Loss G: 0.7274\n",
      "Epoch [19/50] Batch [900/938] Loss D: 1.2745, Loss G: 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_19\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_19\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8735833196027047 ± 0.27347650759692094\n",
      "Frechet Inception Distance: 160.5152460570514\n",
      "Kernel Inception Distance: 0.11229471361826342 ± 1.6996604671033582e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_19.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_19.png\n",
      "Epoch [19/50] Metrics:\n",
      "  Inception Score (IS): 1.873583\n",
      "  Frechet Inception Distance (FID): 160.515246\n",
      "  Kernel Inception Distance (KID): 0.112295\n",
      "Epoch [20/50] Batch [0/938] Loss D: 1.3043, Loss G: 0.7079\n",
      "Epoch [20/50] Batch [100/938] Loss D: 1.2978, Loss G: 0.7914\n",
      "Epoch [20/50] Batch [200/938] Loss D: 1.3563, Loss G: 0.7350\n",
      "Epoch [20/50] Batch [300/938] Loss D: 1.3566, Loss G: 0.8570\n",
      "Epoch [20/50] Batch [400/938] Loss D: 1.3206, Loss G: 0.7909\n",
      "Epoch [20/50] Batch [500/938] Loss D: 1.3356, Loss G: 0.8045\n",
      "Epoch [20/50] Batch [600/938] Loss D: 1.3401, Loss G: 0.8296\n",
      "Epoch [20/50] Batch [700/938] Loss D: 1.3465, Loss G: 0.7843\n",
      "Epoch [20/50] Batch [800/938] Loss D: 1.2721, Loss G: 0.8344\n",
      "Epoch [20/50] Batch [900/938] Loss D: 1.2624, Loss G: 0.8318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_20\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_20\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7756549607211771 ± 0.21349992108786991\n",
      "Frechet Inception Distance: 149.04026217990707\n",
      "Kernel Inception Distance: 0.09061186313629156 ± 1.3598191978091128e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_20.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_20.png\n",
      "Epoch [20/50] Metrics:\n",
      "  Inception Score (IS): 1.775655\n",
      "  Frechet Inception Distance (FID): 149.040262\n",
      "  Kernel Inception Distance (KID): 0.090612\n",
      "Epoch [21/50] Batch [0/938] Loss D: 1.3662, Loss G: 0.8235\n",
      "Epoch [21/50] Batch [100/938] Loss D: 1.2897, Loss G: 0.8012\n",
      "Epoch [21/50] Batch [200/938] Loss D: 1.3077, Loss G: 0.8092\n",
      "Epoch [21/50] Batch [300/938] Loss D: 1.3327, Loss G: 0.9067\n",
      "Epoch [21/50] Batch [400/938] Loss D: 1.2715, Loss G: 0.7563\n",
      "Epoch [21/50] Batch [500/938] Loss D: 1.3590, Loss G: 0.8252\n",
      "Epoch [21/50] Batch [600/938] Loss D: 1.3215, Loss G: 0.8944\n",
      "Epoch [21/50] Batch [700/938] Loss D: 1.3378, Loss G: 0.7123\n",
      "Epoch [21/50] Batch [800/938] Loss D: 1.3645, Loss G: 0.7839\n",
      "Epoch [21/50] Batch [900/938] Loss D: 1.2021, Loss G: 0.7995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_21\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_21\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.797498125349362 ± 0.30823463985777605\n",
      "Frechet Inception Distance: 140.30264197299832\n",
      "Kernel Inception Distance: 0.09580214954557889 ± 1.1642805768935433e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_21.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_21.png\n",
      "Epoch [21/50] Metrics:\n",
      "  Inception Score (IS): 1.797498\n",
      "  Frechet Inception Distance (FID): 140.302642\n",
      "  Kernel Inception Distance (KID): 0.095802\n",
      "Epoch [22/50] Batch [0/938] Loss D: 1.3990, Loss G: 0.7230\n",
      "Epoch [22/50] Batch [100/938] Loss D: 1.2525, Loss G: 0.7002\n",
      "Epoch [22/50] Batch [200/938] Loss D: 1.3325, Loss G: 0.7732\n",
      "Epoch [22/50] Batch [300/938] Loss D: 1.3153, Loss G: 0.8134\n",
      "Epoch [22/50] Batch [400/938] Loss D: 1.2727, Loss G: 0.8488\n",
      "Epoch [22/50] Batch [500/938] Loss D: 1.4006, Loss G: 0.8430\n",
      "Epoch [22/50] Batch [600/938] Loss D: 1.3223, Loss G: 0.7849\n",
      "Epoch [22/50] Batch [700/938] Loss D: 1.2775, Loss G: 0.8152\n",
      "Epoch [22/50] Batch [800/938] Loss D: 1.3094, Loss G: 0.8394\n",
      "Epoch [22/50] Batch [900/938] Loss D: 1.3169, Loss G: 0.9159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_22\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_22\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8309495202800465 ± 0.16664097498821415\n",
      "Frechet Inception Distance: 144.18367515925192\n",
      "Kernel Inception Distance: 0.09028952042261759 ± 1.7093852474401274e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_22.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_22.png\n",
      "Epoch [22/50] Metrics:\n",
      "  Inception Score (IS): 1.830950\n",
      "  Frechet Inception Distance (FID): 144.183675\n",
      "  Kernel Inception Distance (KID): 0.090290\n",
      "Epoch [23/50] Batch [0/938] Loss D: 1.3556, Loss G: 0.7747\n",
      "Epoch [23/50] Batch [100/938] Loss D: 1.3052, Loss G: 0.8562\n",
      "Epoch [23/50] Batch [200/938] Loss D: 1.2444, Loss G: 0.8639\n",
      "Epoch [23/50] Batch [300/938] Loss D: 1.2651, Loss G: 0.7732\n",
      "Epoch [23/50] Batch [400/938] Loss D: 1.4460, Loss G: 0.8404\n",
      "Epoch [23/50] Batch [500/938] Loss D: 1.3066, Loss G: 0.7489\n",
      "Epoch [23/50] Batch [600/938] Loss D: 1.3514, Loss G: 0.7133\n",
      "Epoch [23/50] Batch [700/938] Loss D: 1.3404, Loss G: 0.9297\n",
      "Epoch [23/50] Batch [800/938] Loss D: 1.3228, Loss G: 0.8250\n",
      "Epoch [23/50] Batch [900/938] Loss D: 1.3412, Loss G: 0.8203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_23\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_23\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8251041773529395 ± 0.3783863055586656\n",
      "Frechet Inception Distance: 142.02622791866008\n",
      "Kernel Inception Distance: 0.08889482475462415 ± 1.0205807731630372e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_23.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_23.png\n",
      "Epoch [23/50] Metrics:\n",
      "  Inception Score (IS): 1.825104\n",
      "  Frechet Inception Distance (FID): 142.026228\n",
      "  Kernel Inception Distance (KID): 0.088895\n",
      "Epoch [24/50] Batch [0/938] Loss D: 1.3000, Loss G: 0.7566\n",
      "Epoch [24/50] Batch [100/938] Loss D: 1.4216, Loss G: 0.8935\n",
      "Epoch [24/50] Batch [200/938] Loss D: 1.3287, Loss G: 0.7437\n",
      "Epoch [24/50] Batch [300/938] Loss D: 1.3935, Loss G: 0.7840\n",
      "Epoch [24/50] Batch [400/938] Loss D: 1.4788, Loss G: 0.8049\n",
      "Epoch [24/50] Batch [500/938] Loss D: 1.3356, Loss G: 0.6747\n",
      "Epoch [24/50] Batch [600/938] Loss D: 1.3155, Loss G: 0.8399\n",
      "Epoch [24/50] Batch [700/938] Loss D: 1.2933, Loss G: 0.8263\n",
      "Epoch [24/50] Batch [800/938] Loss D: 1.3093, Loss G: 0.7432\n",
      "Epoch [24/50] Batch [900/938] Loss D: 1.3078, Loss G: 0.7386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_24\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_24\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7528658062991316 ± 0.2153660851738014\n",
      "Frechet Inception Distance: 138.133631287377\n",
      "Kernel Inception Distance: 0.08411255734307435 ± 1.2255261758413177e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_24.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_24.png\n",
      "Epoch [24/50] Metrics:\n",
      "  Inception Score (IS): 1.752866\n",
      "  Frechet Inception Distance (FID): 138.133631\n",
      "  Kernel Inception Distance (KID): 0.084113\n",
      "Epoch [25/50] Batch [0/938] Loss D: 1.3463, Loss G: 0.7996\n",
      "Epoch [25/50] Batch [100/938] Loss D: 1.3832, Loss G: 0.7869\n",
      "Epoch [25/50] Batch [200/938] Loss D: 1.3058, Loss G: 0.8509\n",
      "Epoch [25/50] Batch [300/938] Loss D: 1.2817, Loss G: 0.8202\n",
      "Epoch [25/50] Batch [400/938] Loss D: 1.3813, Loss G: 0.8063\n",
      "Epoch [25/50] Batch [500/938] Loss D: 1.3441, Loss G: 0.7716\n",
      "Epoch [25/50] Batch [600/938] Loss D: 1.3533, Loss G: 0.8001\n",
      "Epoch [25/50] Batch [700/938] Loss D: 1.3492, Loss G: 0.7886\n",
      "Epoch [25/50] Batch [800/938] Loss D: 1.3642, Loss G: 0.7969\n",
      "Epoch [25/50] Batch [900/938] Loss D: 1.3306, Loss G: 0.8161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_25\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_25\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.768942106852545 ± 0.18833516637367254\n",
      "Frechet Inception Distance: 149.1751845334952\n",
      "Kernel Inception Distance: 0.09761328526905612 ± 1.5131193513997082e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_25.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_25.png\n",
      "Epoch [25/50] Metrics:\n",
      "  Inception Score (IS): 1.768942\n",
      "  Frechet Inception Distance (FID): 149.175185\n",
      "  Kernel Inception Distance (KID): 0.097613\n",
      "Epoch [26/50] Batch [0/938] Loss D: 1.3432, Loss G: 0.8266\n",
      "Epoch [26/50] Batch [100/938] Loss D: 1.3372, Loss G: 0.7166\n",
      "Epoch [26/50] Batch [200/938] Loss D: 1.3605, Loss G: 0.7010\n",
      "Epoch [26/50] Batch [300/938] Loss D: 1.3046, Loss G: 0.8336\n",
      "Epoch [26/50] Batch [400/938] Loss D: 1.2820, Loss G: 0.8774\n",
      "Epoch [26/50] Batch [500/938] Loss D: 1.3661, Loss G: 0.9017\n",
      "Epoch [26/50] Batch [600/938] Loss D: 1.3392, Loss G: 0.8125\n",
      "Epoch [26/50] Batch [700/938] Loss D: 1.3369, Loss G: 0.7515\n",
      "Epoch [26/50] Batch [800/938] Loss D: 1.4340, Loss G: 0.7493\n",
      "Epoch [26/50] Batch [900/938] Loss D: 1.3403, Loss G: 0.7511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_26\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_26\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8178892599521004 ± 0.32386108185960616\n",
      "Frechet Inception Distance: 139.16893811020185\n",
      "Kernel Inception Distance: 0.08553172584563981 ± 1.5101773845269637e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_26.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_26.png\n",
      "Epoch [26/50] Metrics:\n",
      "  Inception Score (IS): 1.817889\n",
      "  Frechet Inception Distance (FID): 139.168938\n",
      "  Kernel Inception Distance (KID): 0.085532\n",
      "Epoch [27/50] Batch [0/938] Loss D: 1.2631, Loss G: 0.7919\n",
      "Epoch [27/50] Batch [100/938] Loss D: 1.3285, Loss G: 0.7381\n",
      "Epoch [27/50] Batch [200/938] Loss D: 1.3366, Loss G: 0.9137\n",
      "Epoch [27/50] Batch [300/938] Loss D: 1.2097, Loss G: 0.8360\n",
      "Epoch [27/50] Batch [400/938] Loss D: 1.3220, Loss G: 0.6969\n",
      "Epoch [27/50] Batch [500/938] Loss D: 1.3311, Loss G: 0.8526\n",
      "Epoch [27/50] Batch [600/938] Loss D: 1.3285, Loss G: 0.8243\n",
      "Epoch [27/50] Batch [700/938] Loss D: 1.3357, Loss G: 0.7352\n",
      "Epoch [27/50] Batch [800/938] Loss D: 1.3214, Loss G: 0.7975\n",
      "Epoch [27/50] Batch [900/938] Loss D: 1.3052, Loss G: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_27\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_27\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.885785627944324 ± 0.14899376205790602\n",
      "Frechet Inception Distance: 128.8781961398126\n",
      "Kernel Inception Distance: 0.06520598521308302 ± 9.574867842619956e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_27.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_27.png\n",
      "Epoch [27/50] Metrics:\n",
      "  Inception Score (IS): 1.885786\n",
      "  Frechet Inception Distance (FID): 128.878196\n",
      "  Kernel Inception Distance (KID): 0.065206\n",
      "Epoch [28/50] Batch [0/938] Loss D: 1.4000, Loss G: 0.7459\n",
      "Epoch [28/50] Batch [100/938] Loss D: 1.3471, Loss G: 0.7923\n",
      "Epoch [28/50] Batch [200/938] Loss D: 1.3112, Loss G: 0.7623\n",
      "Epoch [28/50] Batch [300/938] Loss D: 1.3817, Loss G: 0.7741\n",
      "Epoch [28/50] Batch [400/938] Loss D: 1.3113, Loss G: 0.8182\n",
      "Epoch [28/50] Batch [500/938] Loss D: 1.3182, Loss G: 0.7834\n",
      "Epoch [28/50] Batch [600/938] Loss D: 1.3129, Loss G: 0.8942\n",
      "Epoch [28/50] Batch [700/938] Loss D: 1.2879, Loss G: 0.7151\n",
      "Epoch [28/50] Batch [800/938] Loss D: 1.4477, Loss G: 0.8196\n",
      "Epoch [28/50] Batch [900/938] Loss D: 1.3381, Loss G: 0.7945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_28\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_28\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8093641965049412 ± 0.2132138786823682\n",
      "Frechet Inception Distance: 139.09195043355706\n",
      "Kernel Inception Distance: 0.08421272198359174 ± 1.4439843947850042e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_28.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_28.png\n",
      "Epoch [28/50] Metrics:\n",
      "  Inception Score (IS): 1.809364\n",
      "  Frechet Inception Distance (FID): 139.091950\n",
      "  Kernel Inception Distance (KID): 0.084213\n",
      "Epoch [29/50] Batch [0/938] Loss D: 1.2652, Loss G: 0.7746\n",
      "Epoch [29/50] Batch [100/938] Loss D: 1.2762, Loss G: 0.7513\n",
      "Epoch [29/50] Batch [200/938] Loss D: 1.3854, Loss G: 0.8476\n",
      "Epoch [29/50] Batch [300/938] Loss D: 1.3160, Loss G: 0.7886\n",
      "Epoch [29/50] Batch [400/938] Loss D: 1.3222, Loss G: 0.7922\n",
      "Epoch [29/50] Batch [500/938] Loss D: 1.2674, Loss G: 0.7411\n",
      "Epoch [29/50] Batch [600/938] Loss D: 1.2337, Loss G: 0.8042\n",
      "Epoch [29/50] Batch [700/938] Loss D: 1.3148, Loss G: 0.8274\n",
      "Epoch [29/50] Batch [800/938] Loss D: 1.2787, Loss G: 0.7483\n",
      "Epoch [29/50] Batch [900/938] Loss D: 1.3117, Loss G: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_29\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_29\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8358153697073483 ± 0.177768826426416\n",
      "Frechet Inception Distance: 126.2030259232038\n",
      "Kernel Inception Distance: 0.06245182222790177 ± 1.4379147403841947e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_29.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_29.png\n",
      "Epoch [29/50] Metrics:\n",
      "  Inception Score (IS): 1.835815\n",
      "  Frechet Inception Distance (FID): 126.203026\n",
      "  Kernel Inception Distance (KID): 0.062452\n",
      "Epoch [30/50] Batch [0/938] Loss D: 1.4310, Loss G: 0.7395\n",
      "Epoch [30/50] Batch [100/938] Loss D: 1.3595, Loss G: 0.7258\n",
      "Epoch [30/50] Batch [200/938] Loss D: 1.3590, Loss G: 0.7667\n",
      "Epoch [30/50] Batch [300/938] Loss D: 1.3260, Loss G: 0.7603\n",
      "Epoch [30/50] Batch [400/938] Loss D: 1.4192, Loss G: 0.7329\n",
      "Epoch [30/50] Batch [500/938] Loss D: 1.2942, Loss G: 0.6824\n",
      "Epoch [30/50] Batch [600/938] Loss D: 1.2926, Loss G: 0.7683\n",
      "Epoch [30/50] Batch [700/938] Loss D: 1.3530, Loss G: 0.7436\n",
      "Epoch [30/50] Batch [800/938] Loss D: 1.3669, Loss G: 0.8086\n",
      "Epoch [30/50] Batch [900/938] Loss D: 1.3202, Loss G: 0.7624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_30\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_30\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8465791888932366 ± 0.29221184726316224\n",
      "Frechet Inception Distance: 138.82579690821967\n",
      "Kernel Inception Distance: 0.06882025851143744 ± 9.88363128375934e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_30.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_30.png\n",
      "Epoch [30/50] Metrics:\n",
      "  Inception Score (IS): 1.846579\n",
      "  Frechet Inception Distance (FID): 138.825797\n",
      "  Kernel Inception Distance (KID): 0.068820\n",
      "Epoch [31/50] Batch [0/938] Loss D: 1.3140, Loss G: 0.8256\n",
      "Epoch [31/50] Batch [100/938] Loss D: 1.3169, Loss G: 0.8339\n",
      "Epoch [31/50] Batch [200/938] Loss D: 1.3279, Loss G: 0.7555\n",
      "Epoch [31/50] Batch [300/938] Loss D: 1.3989, Loss G: 0.7831\n",
      "Epoch [31/50] Batch [400/938] Loss D: 1.3662, Loss G: 0.7581\n",
      "Epoch [31/50] Batch [500/938] Loss D: 1.3074, Loss G: 0.7474\n",
      "Epoch [31/50] Batch [600/938] Loss D: 1.3053, Loss G: 0.8382\n",
      "Epoch [31/50] Batch [700/938] Loss D: 1.2992, Loss G: 0.7926\n",
      "Epoch [31/50] Batch [800/938] Loss D: 1.3399, Loss G: 0.7665\n",
      "Epoch [31/50] Batch [900/938] Loss D: 1.3694, Loss G: 0.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_31\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_31\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.777841188634366 ± 0.2617052841592126\n",
      "Frechet Inception Distance: 126.68422632791331\n",
      "Kernel Inception Distance: 0.06566771397514941 ± 1.973059045815676e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_31.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_31.png\n",
      "Epoch [31/50] Metrics:\n",
      "  Inception Score (IS): 1.777841\n",
      "  Frechet Inception Distance (FID): 126.684226\n",
      "  Kernel Inception Distance (KID): 0.065668\n",
      "Epoch [32/50] Batch [0/938] Loss D: 1.2925, Loss G: 0.8031\n",
      "Epoch [32/50] Batch [100/938] Loss D: 1.2855, Loss G: 0.7912\n",
      "Epoch [32/50] Batch [200/938] Loss D: 1.3932, Loss G: 0.7678\n",
      "Epoch [32/50] Batch [300/938] Loss D: 1.3006, Loss G: 0.7306\n",
      "Epoch [32/50] Batch [400/938] Loss D: 1.3322, Loss G: 0.8139\n",
      "Epoch [32/50] Batch [500/938] Loss D: 1.3458, Loss G: 0.8123\n",
      "Epoch [32/50] Batch [600/938] Loss D: 1.2849, Loss G: 0.8152\n",
      "Epoch [32/50] Batch [700/938] Loss D: 1.3839, Loss G: 0.8194\n",
      "Epoch [32/50] Batch [800/938] Loss D: 1.3566, Loss G: 0.7773\n",
      "Epoch [32/50] Batch [900/938] Loss D: 1.3001, Loss G: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_32\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_32\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.9099074541116614 ± 0.29697740048179094\n",
      "Frechet Inception Distance: 139.48589592662256\n",
      "Kernel Inception Distance: 0.07419729070057947 ± 7.758019646317533e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_32.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_32.png\n",
      "Epoch [32/50] Metrics:\n",
      "  Inception Score (IS): 1.909907\n",
      "  Frechet Inception Distance (FID): 139.485896\n",
      "  Kernel Inception Distance (KID): 0.074197\n",
      "Epoch [33/50] Batch [0/938] Loss D: 1.2911, Loss G: 0.7750\n",
      "Epoch [33/50] Batch [100/938] Loss D: 1.2666, Loss G: 0.7548\n",
      "Epoch [33/50] Batch [200/938] Loss D: 1.3472, Loss G: 0.8182\n",
      "Epoch [33/50] Batch [300/938] Loss D: 1.3621, Loss G: 0.7758\n",
      "Epoch [33/50] Batch [400/938] Loss D: 1.2874, Loss G: 0.8009\n",
      "Epoch [33/50] Batch [500/938] Loss D: 1.3700, Loss G: 0.8046\n",
      "Epoch [33/50] Batch [600/938] Loss D: 1.3628, Loss G: 0.7350\n",
      "Epoch [33/50] Batch [700/938] Loss D: 1.3812, Loss G: 0.7408\n",
      "Epoch [33/50] Batch [800/938] Loss D: 1.3066, Loss G: 0.7800\n",
      "Epoch [33/50] Batch [900/938] Loss D: 1.3071, Loss G: 0.7669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_33\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_33\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7447731040305592 ± 0.19709217599264536\n",
      "Frechet Inception Distance: 123.24461946557977\n",
      "Kernel Inception Distance: 0.06491511159473001 ± 6.297090395638304e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_33.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_33.png\n",
      "Epoch [33/50] Metrics:\n",
      "  Inception Score (IS): 1.744773\n",
      "  Frechet Inception Distance (FID): 123.244619\n",
      "  Kernel Inception Distance (KID): 0.064915\n",
      "Epoch [34/50] Batch [0/938] Loss D: 1.3299, Loss G: 0.7291\n",
      "Epoch [34/50] Batch [100/938] Loss D: 1.3964, Loss G: 0.8988\n",
      "Epoch [34/50] Batch [200/938] Loss D: 1.3500, Loss G: 0.8190\n",
      "Epoch [34/50] Batch [300/938] Loss D: 1.3360, Loss G: 0.8869\n",
      "Epoch [34/50] Batch [400/938] Loss D: 1.3383, Loss G: 0.7503\n",
      "Epoch [34/50] Batch [500/938] Loss D: 1.3018, Loss G: 0.7857\n",
      "Epoch [34/50] Batch [600/938] Loss D: 1.3250, Loss G: 0.8485\n",
      "Epoch [34/50] Batch [700/938] Loss D: 1.2743, Loss G: 0.7485\n",
      "Epoch [34/50] Batch [800/938] Loss D: 1.2517, Loss G: 0.8108\n",
      "Epoch [34/50] Batch [900/938] Loss D: 1.3844, Loss G: 0.8693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_34\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_34\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7205349234744385 ± 0.23270812297442245\n",
      "Frechet Inception Distance: 133.40892910408826\n",
      "Kernel Inception Distance: 0.07425133224517583 ± 1.3642539636857541e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_34.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_34.png\n",
      "Epoch [34/50] Metrics:\n",
      "  Inception Score (IS): 1.720535\n",
      "  Frechet Inception Distance (FID): 133.408929\n",
      "  Kernel Inception Distance (KID): 0.074251\n",
      "Epoch [35/50] Batch [0/938] Loss D: 1.3310, Loss G: 0.6806\n",
      "Epoch [35/50] Batch [100/938] Loss D: 1.3232, Loss G: 0.8251\n",
      "Epoch [35/50] Batch [200/938] Loss D: 1.3147, Loss G: 0.7492\n",
      "Epoch [35/50] Batch [300/938] Loss D: 1.2813, Loss G: 0.7619\n",
      "Epoch [35/50] Batch [400/938] Loss D: 1.3071, Loss G: 0.7210\n",
      "Epoch [35/50] Batch [500/938] Loss D: 1.2863, Loss G: 0.7623\n",
      "Epoch [35/50] Batch [600/938] Loss D: 1.3173, Loss G: 0.7518\n",
      "Epoch [35/50] Batch [700/938] Loss D: 1.3358, Loss G: 0.8071\n",
      "Epoch [35/50] Batch [800/938] Loss D: 1.2897, Loss G: 0.7505\n",
      "Epoch [35/50] Batch [900/938] Loss D: 1.2451, Loss G: 0.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_35\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_35\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 2.032203471035576 ± 0.35934905475331824\n",
      "Frechet Inception Distance: 131.42725655949315\n",
      "Kernel Inception Distance: 0.06321692678663446 ± 8.44957597096889e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_35.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_35.png\n",
      "Epoch [35/50] Metrics:\n",
      "  Inception Score (IS): 2.032203\n",
      "  Frechet Inception Distance (FID): 131.427257\n",
      "  Kernel Inception Distance (KID): 0.063217\n",
      "Epoch [36/50] Batch [0/938] Loss D: 1.4329, Loss G: 0.7277\n",
      "Epoch [36/50] Batch [100/938] Loss D: 1.3226, Loss G: 0.7425\n",
      "Epoch [36/50] Batch [200/938] Loss D: 1.2681, Loss G: 0.7747\n",
      "Epoch [36/50] Batch [300/938] Loss D: 1.3516, Loss G: 0.8286\n",
      "Epoch [36/50] Batch [400/938] Loss D: 1.3350, Loss G: 0.8198\n",
      "Epoch [36/50] Batch [500/938] Loss D: 1.3604, Loss G: 0.7873\n",
      "Epoch [36/50] Batch [600/938] Loss D: 1.3105, Loss G: 0.8244\n",
      "Epoch [36/50] Batch [700/938] Loss D: 1.3716, Loss G: 0.8047\n",
      "Epoch [36/50] Batch [800/938] Loss D: 1.3408, Loss G: 0.8505\n",
      "Epoch [36/50] Batch [900/938] Loss D: 1.3685, Loss G: 0.8464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_36\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_36\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8722183479102665 ± 0.40173198747549416\n",
      "Frechet Inception Distance: 119.30040694444344\n",
      "Kernel Inception Distance: 0.05499121790840496 ± 1.7603124014989322e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_36.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_36.png\n",
      "Epoch [36/50] Metrics:\n",
      "  Inception Score (IS): 1.872218\n",
      "  Frechet Inception Distance (FID): 119.300407\n",
      "  Kernel Inception Distance (KID): 0.054991\n",
      "Epoch [37/50] Batch [0/938] Loss D: 1.3073, Loss G: 0.8110\n",
      "Epoch [37/50] Batch [100/938] Loss D: 1.3002, Loss G: 0.8143\n",
      "Epoch [37/50] Batch [200/938] Loss D: 1.3607, Loss G: 0.7314\n",
      "Epoch [37/50] Batch [300/938] Loss D: 1.2549, Loss G: 0.7598\n",
      "Epoch [37/50] Batch [400/938] Loss D: 1.2642, Loss G: 0.7746\n",
      "Epoch [37/50] Batch [500/938] Loss D: 1.3190, Loss G: 0.7344\n",
      "Epoch [37/50] Batch [600/938] Loss D: 1.3031, Loss G: 0.8019\n",
      "Epoch [37/50] Batch [700/938] Loss D: 1.3427, Loss G: 0.7490\n",
      "Epoch [37/50] Batch [800/938] Loss D: 1.3458, Loss G: 0.7117\n",
      "Epoch [37/50] Batch [900/938] Loss D: 1.3469, Loss G: 0.7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_37\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_37\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 2.0054404957928993 ± 0.3427184661007749\n",
      "Frechet Inception Distance: 133.56766043640482\n",
      "Kernel Inception Distance: 0.06203351157052186 ± 1.8551722478324792e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_37.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_37.png\n",
      "Epoch [37/50] Metrics:\n",
      "  Inception Score (IS): 2.005440\n",
      "  Frechet Inception Distance (FID): 133.567660\n",
      "  Kernel Inception Distance (KID): 0.062034\n",
      "Epoch [38/50] Batch [0/938] Loss D: 1.3013, Loss G: 0.8010\n",
      "Epoch [38/50] Batch [100/938] Loss D: 1.2758, Loss G: 0.8349\n",
      "Epoch [38/50] Batch [200/938] Loss D: 1.3185, Loss G: 0.8812\n",
      "Epoch [38/50] Batch [300/938] Loss D: 1.2781, Loss G: 0.9262\n",
      "Epoch [38/50] Batch [400/938] Loss D: 1.3008, Loss G: 0.8152\n",
      "Epoch [38/50] Batch [500/938] Loss D: 1.3429, Loss G: 0.7495\n",
      "Epoch [38/50] Batch [600/938] Loss D: 1.3180, Loss G: 0.7919\n",
      "Epoch [38/50] Batch [700/938] Loss D: 1.3244, Loss G: 0.7812\n",
      "Epoch [38/50] Batch [800/938] Loss D: 1.3684, Loss G: 0.8500\n",
      "Epoch [38/50] Batch [900/938] Loss D: 1.3203, Loss G: 0.8546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_38\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_38\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.9296162637488687 ± 0.3227149852752643\n",
      "Frechet Inception Distance: 127.90350433171037\n",
      "Kernel Inception Distance: 0.062454189005352066 ± 1.812334118312527e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_38.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_38.png\n",
      "Epoch [38/50] Metrics:\n",
      "  Inception Score (IS): 1.929616\n",
      "  Frechet Inception Distance (FID): 127.903504\n",
      "  Kernel Inception Distance (KID): 0.062454\n",
      "Epoch [39/50] Batch [0/938] Loss D: 1.2884, Loss G: 0.8016\n",
      "Epoch [39/50] Batch [100/938] Loss D: 1.4272, Loss G: 0.8440\n",
      "Epoch [39/50] Batch [200/938] Loss D: 1.3787, Loss G: 0.8075\n",
      "Epoch [39/50] Batch [300/938] Loss D: 1.4663, Loss G: 0.7964\n",
      "Epoch [39/50] Batch [400/938] Loss D: 1.3103, Loss G: 0.8073\n",
      "Epoch [39/50] Batch [500/938] Loss D: 1.3412, Loss G: 0.7477\n",
      "Epoch [39/50] Batch [600/938] Loss D: 1.2763, Loss G: 0.8440\n",
      "Epoch [39/50] Batch [700/938] Loss D: 1.3549, Loss G: 0.8941\n",
      "Epoch [39/50] Batch [800/938] Loss D: 1.3295, Loss G: 0.8161\n",
      "Epoch [39/50] Batch [900/938] Loss D: 1.2746, Loss G: 0.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_39\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_39\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.7814799782220976 ± 0.18220713380598003\n",
      "Frechet Inception Distance: 113.3095304707767\n",
      "Kernel Inception Distance: 0.042394165349385 ± 1.7986724240285084e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_39.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_39.png\n",
      "Epoch [39/50] Metrics:\n",
      "  Inception Score (IS): 1.781480\n",
      "  Frechet Inception Distance (FID): 113.309530\n",
      "  Kernel Inception Distance (KID): 0.042394\n",
      "Epoch [40/50] Batch [0/938] Loss D: 1.3330, Loss G: 0.8377\n",
      "Epoch [40/50] Batch [100/938] Loss D: 1.3261, Loss G: 0.8051\n",
      "Epoch [40/50] Batch [200/938] Loss D: 1.1896, Loss G: 0.8560\n",
      "Epoch [40/50] Batch [300/938] Loss D: 1.2611, Loss G: 0.7477\n",
      "Epoch [40/50] Batch [400/938] Loss D: 1.3245, Loss G: 0.7826\n",
      "Epoch [40/50] Batch [500/938] Loss D: 1.2930, Loss G: 0.7209\n",
      "Epoch [40/50] Batch [600/938] Loss D: 1.3438, Loss G: 0.7852\n",
      "Epoch [40/50] Batch [700/938] Loss D: 1.3455, Loss G: 0.7644\n",
      "Epoch [40/50] Batch [800/938] Loss D: 1.2810, Loss G: 0.7581\n",
      "Epoch [40/50] Batch [900/938] Loss D: 1.3106, Loss G: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_40\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_40\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8890074338732525 ± 0.2287596680065946\n",
      "Frechet Inception Distance: 119.4155467410448\n",
      "Kernel Inception Distance: 0.053794226419357986 ± 1.6318058576007952e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_40.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_40.png\n",
      "Epoch [40/50] Metrics:\n",
      "  Inception Score (IS): 1.889007\n",
      "  Frechet Inception Distance (FID): 119.415547\n",
      "  Kernel Inception Distance (KID): 0.053794\n",
      "Epoch [41/50] Batch [0/938] Loss D: 1.3103, Loss G: 0.7754\n",
      "Epoch [41/50] Batch [100/938] Loss D: 1.3063, Loss G: 0.8071\n",
      "Epoch [41/50] Batch [200/938] Loss D: 1.3171, Loss G: 0.7863\n",
      "Epoch [41/50] Batch [300/938] Loss D: 1.3977, Loss G: 0.7644\n",
      "Epoch [41/50] Batch [400/938] Loss D: 1.4158, Loss G: 0.8108\n",
      "Epoch [41/50] Batch [500/938] Loss D: 1.3518, Loss G: 0.7285\n",
      "Epoch [41/50] Batch [600/938] Loss D: 1.2841, Loss G: 0.7648\n",
      "Epoch [41/50] Batch [700/938] Loss D: 1.2346, Loss G: 0.7766\n",
      "Epoch [41/50] Batch [800/938] Loss D: 1.3649, Loss G: 0.7680\n",
      "Epoch [41/50] Batch [900/938] Loss D: 1.3729, Loss G: 0.8368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_41\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_41\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.9516484128051013 ± 0.26912176689284084\n",
      "Frechet Inception Distance: 125.93189477814883\n",
      "Kernel Inception Distance: 0.05458044332171231 ± 1.263890172759681e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_41.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_41.png\n",
      "Epoch [41/50] Metrics:\n",
      "  Inception Score (IS): 1.951648\n",
      "  Frechet Inception Distance (FID): 125.931895\n",
      "  Kernel Inception Distance (KID): 0.054580\n",
      "Epoch [42/50] Batch [0/938] Loss D: 1.3167, Loss G: 0.7538\n",
      "Epoch [42/50] Batch [100/938] Loss D: 1.3457, Loss G: 0.8666\n",
      "Epoch [42/50] Batch [200/938] Loss D: 1.3725, Loss G: 0.7827\n",
      "Epoch [42/50] Batch [300/938] Loss D: 1.3102, Loss G: 0.8414\n",
      "Epoch [42/50] Batch [400/938] Loss D: 1.3955, Loss G: 0.7525\n",
      "Epoch [42/50] Batch [500/938] Loss D: 1.2453, Loss G: 0.8687\n",
      "Epoch [42/50] Batch [600/938] Loss D: 1.2789, Loss G: 0.8706\n",
      "Epoch [42/50] Batch [700/938] Loss D: 1.2646, Loss G: 0.8629\n",
      "Epoch [42/50] Batch [800/938] Loss D: 1.2341, Loss G: 0.7215\n",
      "Epoch [42/50] Batch [900/938] Loss D: 1.3258, Loss G: 0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_42\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_42\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.841979660378716 ± 0.2964603987849158\n",
      "Frechet Inception Distance: 118.46512264019833\n",
      "Kernel Inception Distance: 0.05373154057396775 ± 8.709989830141865e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_42.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_42.png\n",
      "Epoch [42/50] Metrics:\n",
      "  Inception Score (IS): 1.841980\n",
      "  Frechet Inception Distance (FID): 118.465123\n",
      "  Kernel Inception Distance (KID): 0.053732\n",
      "Epoch [43/50] Batch [0/938] Loss D: 1.4298, Loss G: 0.8034\n",
      "Epoch [43/50] Batch [100/938] Loss D: 1.3403, Loss G: 0.8528\n",
      "Epoch [43/50] Batch [200/938] Loss D: 1.3582, Loss G: 0.7961\n",
      "Epoch [43/50] Batch [300/938] Loss D: 1.3740, Loss G: 0.7579\n",
      "Epoch [43/50] Batch [400/938] Loss D: 1.3254, Loss G: 0.7856\n",
      "Epoch [43/50] Batch [500/938] Loss D: 1.3179, Loss G: 0.8626\n",
      "Epoch [43/50] Batch [600/938] Loss D: 1.3408, Loss G: 0.7881\n",
      "Epoch [43/50] Batch [700/938] Loss D: 1.3129, Loss G: 0.7687\n",
      "Epoch [43/50] Batch [800/938] Loss D: 1.3682, Loss G: 0.9150\n",
      "Epoch [43/50] Batch [900/938] Loss D: 1.3101, Loss G: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_43\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_43\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.9356283516670039 ± 0.22997641207465547\n",
      "Frechet Inception Distance: 113.15785421572019\n",
      "Kernel Inception Distance: 0.04415943932911709 ± 1.0182455303221998e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_43.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_43.png\n",
      "Epoch [43/50] Metrics:\n",
      "  Inception Score (IS): 1.935628\n",
      "  Frechet Inception Distance (FID): 113.157854\n",
      "  Kernel Inception Distance (KID): 0.044159\n",
      "Epoch [44/50] Batch [0/938] Loss D: 1.3620, Loss G: 0.8292\n",
      "Epoch [44/50] Batch [100/938] Loss D: 1.3854, Loss G: 0.7486\n",
      "Epoch [44/50] Batch [200/938] Loss D: 1.3282, Loss G: 0.7242\n",
      "Epoch [44/50] Batch [300/938] Loss D: 1.3770, Loss G: 0.7041\n",
      "Epoch [44/50] Batch [400/938] Loss D: 1.2647, Loss G: 0.9289\n",
      "Epoch [44/50] Batch [500/938] Loss D: 1.2858, Loss G: 0.7660\n",
      "Epoch [44/50] Batch [600/938] Loss D: 1.2947, Loss G: 0.7872\n",
      "Epoch [44/50] Batch [700/938] Loss D: 1.2776, Loss G: 0.9830\n",
      "Epoch [44/50] Batch [800/938] Loss D: 1.3028, Loss G: 0.7401\n",
      "Epoch [44/50] Batch [900/938] Loss D: 1.2720, Loss G: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_44\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_44\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.9758854692301864 ± 0.2765272879568855\n",
      "Frechet Inception Distance: 112.65759876119606\n",
      "Kernel Inception Distance: 0.0391531951465303 ± 1.0604878635242692e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_44.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_44.png\n",
      "Epoch [44/50] Metrics:\n",
      "  Inception Score (IS): 1.975885\n",
      "  Frechet Inception Distance (FID): 112.657599\n",
      "  Kernel Inception Distance (KID): 0.039153\n",
      "Epoch [45/50] Batch [0/938] Loss D: 1.3454, Loss G: 0.7356\n",
      "Epoch [45/50] Batch [100/938] Loss D: 1.2688, Loss G: 0.8721\n",
      "Epoch [45/50] Batch [200/938] Loss D: 1.3637, Loss G: 0.7821\n",
      "Epoch [45/50] Batch [300/938] Loss D: 1.3221, Loss G: 0.8130\n",
      "Epoch [45/50] Batch [400/938] Loss D: 1.3243, Loss G: 0.7137\n",
      "Epoch [45/50] Batch [500/938] Loss D: 1.3396, Loss G: 0.7962\n",
      "Epoch [45/50] Batch [600/938] Loss D: 1.3246, Loss G: 0.8034\n",
      "Epoch [45/50] Batch [700/938] Loss D: 1.3751, Loss G: 0.8117\n",
      "Epoch [45/50] Batch [800/938] Loss D: 1.3123, Loss G: 0.7718\n",
      "Epoch [45/50] Batch [900/938] Loss D: 1.2986, Loss G: 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_45\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_45\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.853687831844415 ± 0.4068917957150726\n",
      "Frechet Inception Distance: 121.08373285791545\n",
      "Kernel Inception Distance: 0.05927860036728885 ± 1.5672933223970735e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_45.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_45.png\n",
      "Epoch [45/50] Metrics:\n",
      "  Inception Score (IS): 1.853688\n",
      "  Frechet Inception Distance (FID): 121.083733\n",
      "  Kernel Inception Distance (KID): 0.059279\n",
      "Epoch [46/50] Batch [0/938] Loss D: 1.3759, Loss G: 0.6874\n",
      "Epoch [46/50] Batch [100/938] Loss D: 1.3417, Loss G: 0.8211\n",
      "Epoch [46/50] Batch [200/938] Loss D: 1.3375, Loss G: 0.8172\n",
      "Epoch [46/50] Batch [300/938] Loss D: 1.2834, Loss G: 0.8947\n",
      "Epoch [46/50] Batch [400/938] Loss D: 1.3331, Loss G: 0.8353\n",
      "Epoch [46/50] Batch [500/938] Loss D: 1.3256, Loss G: 0.6826\n",
      "Epoch [46/50] Batch [600/938] Loss D: 1.2954, Loss G: 0.7135\n",
      "Epoch [46/50] Batch [700/938] Loss D: 1.3078, Loss G: 0.7392\n",
      "Epoch [46/50] Batch [800/938] Loss D: 1.3243, Loss G: 0.7691\n",
      "Epoch [46/50] Batch [900/938] Loss D: 1.3073, Loss G: 0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_46\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_46\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.926417458846941 ± 0.20965578881017113\n",
      "Frechet Inception Distance: 119.5541097570732\n",
      "Kernel Inception Distance: 0.04832574439427207 ± 1.493218506784397e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_46.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_46.png\n",
      "Epoch [46/50] Metrics:\n",
      "  Inception Score (IS): 1.926417\n",
      "  Frechet Inception Distance (FID): 119.554110\n",
      "  Kernel Inception Distance (KID): 0.048326\n",
      "Epoch [47/50] Batch [0/938] Loss D: 1.3701, Loss G: 0.8173\n",
      "Epoch [47/50] Batch [100/938] Loss D: 1.4010, Loss G: 0.8640\n",
      "Epoch [47/50] Batch [200/938] Loss D: 1.4255, Loss G: 0.8626\n",
      "Epoch [47/50] Batch [300/938] Loss D: 1.3487, Loss G: 0.8440\n",
      "Epoch [47/50] Batch [400/938] Loss D: 1.3082, Loss G: 0.7916\n",
      "Epoch [47/50] Batch [500/938] Loss D: 1.2811, Loss G: 0.7960\n",
      "Epoch [47/50] Batch [600/938] Loss D: 1.4499, Loss G: 0.8266\n",
      "Epoch [47/50] Batch [700/938] Loss D: 1.3669, Loss G: 0.8700\n",
      "Epoch [47/50] Batch [800/938] Loss D: 1.3750, Loss G: 0.7152\n",
      "Epoch [47/50] Batch [900/938] Loss D: 1.2836, Loss G: 0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_47\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_47\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8823328116106341 ± 0.321896172151588\n",
      "Frechet Inception Distance: 116.03238343378072\n",
      "Kernel Inception Distance: 0.05441649236376339 ± 1.1646880998660805e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_47.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_47.png\n",
      "Epoch [47/50] Metrics:\n",
      "  Inception Score (IS): 1.882333\n",
      "  Frechet Inception Distance (FID): 116.032383\n",
      "  Kernel Inception Distance (KID): 0.054416\n",
      "Epoch [48/50] Batch [0/938] Loss D: 1.2732, Loss G: 0.7697\n",
      "Epoch [48/50] Batch [100/938] Loss D: 1.3557, Loss G: 0.9346\n",
      "Epoch [48/50] Batch [200/938] Loss D: 1.3143, Loss G: 0.8821\n",
      "Epoch [48/50] Batch [300/938] Loss D: 1.3167, Loss G: 0.8847\n",
      "Epoch [48/50] Batch [400/938] Loss D: 1.2979, Loss G: 0.8336\n",
      "Epoch [48/50] Batch [500/938] Loss D: 1.3454, Loss G: 0.7781\n",
      "Epoch [48/50] Batch [600/938] Loss D: 1.3020, Loss G: 0.8671\n",
      "Epoch [48/50] Batch [700/938] Loss D: 1.3562, Loss G: 0.7655\n",
      "Epoch [48/50] Batch [800/938] Loss D: 1.3474, Loss G: 0.9008\n",
      "Epoch [48/50] Batch [900/938] Loss D: 1.3520, Loss G: 0.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_48\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_48\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.8686054224989426 ± 0.389867952958585\n",
      "Frechet Inception Distance: 120.23983508315428\n",
      "Kernel Inception Distance: 0.054668385944669315 ± 2.0745956422091671e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_48.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_48.png\n",
      "Epoch [48/50] Metrics:\n",
      "  Inception Score (IS): 1.868605\n",
      "  Frechet Inception Distance (FID): 120.239835\n",
      "  Kernel Inception Distance (KID): 0.054668\n",
      "Epoch [49/50] Batch [0/938] Loss D: 1.3231, Loss G: 0.8714\n",
      "Epoch [49/50] Batch [100/938] Loss D: 1.3558, Loss G: 0.8016\n",
      "Epoch [49/50] Batch [200/938] Loss D: 1.3049, Loss G: 0.8047\n",
      "Epoch [49/50] Batch [300/938] Loss D: 1.2752, Loss G: 0.7893\n",
      "Epoch [49/50] Batch [400/938] Loss D: 1.3142, Loss G: 0.7538\n",
      "Epoch [49/50] Batch [500/938] Loss D: 1.3126, Loss G: 0.7089\n",
      "Epoch [49/50] Batch [600/938] Loss D: 1.3078, Loss G: 0.7859\n",
      "Epoch [49/50] Batch [700/938] Loss D: 1.3151, Loss G: 0.7460\n",
      "Epoch [49/50] Batch [800/938] Loss D: 1.3267, Loss G: 0.9248\n",
      "Epoch [49/50] Batch [900/938] Loss D: 1.3467, Loss G: 0.8626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_49\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_49\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.882167532104324 ± 0.25034112329760727\n",
      "Frechet Inception Distance: 121.65068950406547\n",
      "Kernel Inception Distance: 0.050570225110129687 ± 2.0783362819431818e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_49.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_49.png\n",
      "Epoch [49/50] Metrics:\n",
      "  Inception Score (IS): 1.882168\n",
      "  Frechet Inception Distance (FID): 121.650690\n",
      "  Kernel Inception Distance (KID): 0.050570\n",
      "Epoch [50/50] Batch [0/938] Loss D: 1.2696, Loss G: 0.8421\n",
      "Epoch [50/50] Batch [100/938] Loss D: 1.2895, Loss G: 0.7297\n",
      "Epoch [50/50] Batch [200/938] Loss D: 1.2680, Loss G: 0.7597\n",
      "Epoch [50/50] Batch [300/938] Loss D: 1.3785, Loss G: 0.7647\n",
      "Epoch [50/50] Batch [400/938] Loss D: 1.3312, Loss G: 0.7357\n",
      "Epoch [50/50] Batch [500/938] Loss D: 1.3139, Loss G: 0.7857\n",
      "Epoch [50/50] Batch [600/938] Loss D: 1.3768, Loss G: 0.7935\n",
      "Epoch [50/50] Batch [700/938] Loss D: 1.3255, Loss G: 0.7808\n",
      "Epoch [50/50] Batch [800/938] Loss D: 1.2670, Loss G: 0.8220\n",
      "Epoch [50/50] Batch [900/938] Loss D: 1.2970, Loss G: 0.8026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased', '2048']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"./metrics/fake_epoch_50\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Extracting features from input2\n",
      "Looking for samples non-recursivelty in \"./metrics/real_epoch_50\" with extensions png,jpg,jpeg\n",
      "Found 64 samples\n",
      "Processing samples\n",
      "Inception Score: 1.9413465208333727 ± 0.153688860047775\n",
      "Frechet Inception Distance: 118.4055350183103\n",
      "Kernel Inception Distance: 0.05556056859001281 ± 4.166088187994252e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_50.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_50.png\n",
      "Epoch [50/50] Metrics:\n",
      "  Inception Score (IS): 1.941347\n",
      "  Frechet Inception Distance (FID): 118.405535\n",
      "  Kernel Inception Distance (KID): 0.055561\n"
     ]
    }
   ],
   "source": [
    "best_model_path =  \"best.pt\"\n",
    "best_fid = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "        # [EN] Обучение дискриминатора\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device) + 0.05 * torch.randn(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device) + 0.05 * torch.randn(batch_size, 1).to(device)\n",
    "        real_labels = torch.clamp(real_labels, 0, 1)\n",
    "        fake_labels = torch.clamp(fake_labels, 0, 1)\n",
    "\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = generator(z).detach()\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real_labels)\n",
    "        fake_loss = adversarial_loss(discriminator(fake_imgs), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # [EN] Обучение генератора\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(fake_imgs), real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # [EN] Логирование каждые 100 батчей\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch [{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss D: {d_loss.item():.4f}, Loss G: {g_loss.item():.4f}\")\n",
    "\n",
    "    # [EN] Вычисление KID\n",
    "    metrics = calculate_all_metrics(generator, dataloader, epoch + 1, latent_dim, device, num_images=64)\n",
    "    generate_and_save_images(generator, epoch + 1, fake_imgs, real_imgs)\n",
    "    # [EN]update best model\n",
    "    if metrics['frechet_inception_distance'] < best_fid:\n",
    "        best_fid = metrics['frechet_inception_distance']\n",
    "        torch.save(generator.state_dict(), best_model_path)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Metrics:\")\n",
    "    print(f\"  Inception Score (IS): {metrics['inception_score_mean']:.6f}\")\n",
    "    print(f\"  Frechet Inception Distance (FID): {metrics['frechet_inception_distance']:.6f}\")\n",
    "    print(f\"  Kernel Inception Distance (KID): {metrics['kernel_inception_distance_mean']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pb0b6nhkfa--",
    "outputId": "1ecfb051-4e2c-4ec2-baa0-8d1e4e3cf178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake images saved to: ./generated_images/fid_fake_epoch_best.png\n",
      "Real images saved to: ./generated_images/fid_real_epoch_best.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-94994b2e554f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_generator.load_state_dict(torch.load(best_model_path))\n"
     ]
    }
   ],
   "source": [
    "best_generator = ImprovedGenerator(latent_dim, img_size, channels).to(device)\n",
    "best_generator.load_state_dict(torch.load(best_model_path))\n",
    "best_generator.eval()\n",
    "real_imgs = next(iter(dataloader))[0].to(device)\n",
    "z = torch.randn(real_imgs.size(0), latent_dim).to(device)\n",
    "fake_imgs = best_generator(z)\n",
    "generate_and_save_images(best_generator, \"best\", fake_imgs, real_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCdTYGYC_XUN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
